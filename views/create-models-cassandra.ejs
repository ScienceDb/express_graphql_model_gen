'use strict';

const _ = require('lodash');
const Sequelize = require('sequelize');
const dict = require('../../utils/graphql-sequelize-types');
const searchArg = require('../../utils/search-argument');
const globals = require('../../config/globals');
const validatorUtil = require('../../utils/validatorUtil');
const fileTools = require('../../utils/file-tools');
const helpersAcl = require('../../utils/helpers-acl');
const email = require('../../utils/email');
const fs = require('fs');
const path = require('path');
const os = require('os');
const uuidv4 = require('uuidv4');
const helper = require('../../utils/helper');
const models = require(path.join(__dirname, '..', 'index.js'));
const moment = require('moment');
const client = require('../../utils/cassandra-client');
const Uuid = require('cassandra-driver').types.Uuid;

// An exact copy of the the model definition that comes from the .json file
const definition = <%- definition -%>;

/**
 * module - Creates a sequelize model
 *
 * @param  {object} sequelize Sequelize instance.
 * @param  {object} DataTypes Allowed sequelize data types.
 * @return {object}           Sequelize model with associations defined
 */

module.exports = class <%- name -%> /* extends Sequelize.Model */ {
  constructor(input, initMessage) {
    if (initMessage) {
      if (initMessage.rows) {
        delete initMessage.rows;
      }
      this.initMessage = initMessage;
    }
    for (let key of Object.keys(input)) {
      this[key] = input[key];
    }
  }

  /*static init(sequelize, DataTypes){
    return super.init({

        <%if(!defaultId){-%>
        <%- idAttribute -%> : {
          type : Sequelize[ dict['<%- idAttributeType %>'] ],
          primaryKey: true
        },
        <%}-%>
      <% let keys = Object.keys(attributes) -%>
      <%for (let i=0; i< keys.length; i++) {-%>
        <% let type_seq =  attributes[ keys[i] ] -%>
        <%=  keys[i] %>: {
            type: Sequelize[ dict['<%= type_seq %>'] ]<% if(type_seq === 'Time' ){-%>,
            get(){
              let <%=  keys[i] %> = this.getDataValue('<%=  keys[i] %>');
              if(<%=  keys[i] %> !== null ){
                let m = moment(<%=  keys[i] %>, "HH:mm:ss.SSS[Z]");
                if(m.isValid()){
                  return m.format("HH:mm:ss.SSS[Z]");
                }
              }
            }
            <%}-%>
        }
        <%if(i !== (keys.length -1) ){ -%>,<%}-%>
      <%}-%>


    },{ <%if(indices !== undefined){let string_indices = indices.map(x => { return "'" + x + "'" }) -%>
      indexes: [<%- string_indices.join() -%> ], <%}-%>
      modelName: "<%- nameLc -%>",
      tableName: "<%-namePl-%>",
      sequelize
     } );
  }

  static associate(models){
    <% for(var key in associationsArguments){ -%>
      <%for(let i=0; i< associationsArguments[key].length; i++){-%>
        <%if (key !== 'associations'){-%>
          <%if(associationsArguments[key][i].targetStorageType === 'cassandra'){-%>
            <%if (associationsArguments[key][i].type === 'to_one' && associationsArguments[key][i].keyIn !== associationsArguments[key][i].target){-%>
              <%- name -%>.belongsTo(models.<%= associationsArguments[key][i].target_lc -%>
            <%}-%>
            <% if (associationsArguments[key][i].type === 'to_one' && associationsArguments[key][i].keyIn === associationsArguments[key][i].target){-%>
              <%- name -%>.hasOne(models.<%= associationsArguments[key][i].target_lc -%>
            <%}-%>
            <% if (associationsArguments[key][i].type === 'to_many' && associationsArguments[key][i].keyIn === associationsArguments[key][i].target){-%>
              <%- name -%>.hasMany(models.<%= associationsArguments[key][i].target_lc -%>
            <%}-%>
            <% if (associationsArguments[key][i].type === 'to_many_through_sql_cross_table' ){-%>
              <%- name -%>.belongsToMany(models.<%= associationsArguments[key][i].target_lc -%>
            <%}-%>
            <% if(key === 'to_many_through_sql_cross_table'){ -%> ,{as: '<%= associationsArguments[key][i].name -%>',
            foreignKey:'<%= associationsArguments[key][i].sourceKey -%>',
            through : '<%= associationsArguments[key][i].keysIn -%>',
            onDelete: 'CASCADE'}  <%}else{ -%>
            ,{as: '<%= associationsArguments[key][i].name -%>', foreignKey:'<%= associationsArguments[key][i].targetKey -%>' }
            <%}-%>);
          <%}-%>
        <%}-%>
      <%}-%>
    <% } -%>
  }*/

  static get name(){
    return "<%- nameLc -%>";
  }

  static async readById(id){
    const query = `SELECT * FROM <%- namePl -%> WHERE <%- idAttribute -%> = ?`;
    let queryResult = await client.execute(query, [ <% if (idAttributeType.toLowerCase() === 'uuid') { -%>Uuid.fromString(id)<% } else { %>id<%}-%> ], { prepare: true });
    let firstResult = queryResult.first();
    let item = new <%- name -%>(firstResult, queryResult);
    if (item === null) {
      throw new Error(`Record with ID = "${id}" does not exist`);
    }
    try {
      await validatorUtil.ifHasValidatorFunctionInvoke('validateAfterRead', this, item);
      return item;
    } catch (err) {
      return err
    };
  }

  static async countRecords(search, filtering){
    let options = {};
    let result = 0;
    let arg_cassandra = ';';
    if (search !== undefined) {

      //check
      if(typeof search !== 'object') {
        throw new Error('Illegal "search" argument type, it must be an object.');
      }

      let arg = new searchArg(search);
      /*let arg_sequelize = arg.toSequelize();
      options['where'] = arg_sequelize;*/
      arg_cassandra = ' ' + arg.toCassandra('<%- idAttribute -%>', filtering);
    }
    const query = 'SELECT COUNT(*) AS count FROM <%- namePl -%>' + arg_cassandra;
    let queryResult = await client.execute(query);
    let item = queryResult.first();
    result = parseInt(item['count']);
    return result;
  }

  static readAll(search, order, pagination){
    throw new Error('Limit-offset based pagination is not supported by Cassandra');
  }

  static async readAllCursor(search, pagination, filteringAllowed){
    // === Set variables ===

    let offsetCursor = pagination ? pagination.after : null;
    let arg_cassandra = ';';
    let searchTerms = search;

    // === Set pagination offset if needed ===

    /*
    * In this section, a special operator is used: "tgt", meaning "TOKEN > TOKEN".
    * This operator is implemented in utils/search-argument.js, toCassandra(idAttribute, allowFiltering)
    *
    * The Cassandra database is ordered by the TOKEN of the ID value, so if we want to cut away entries above the cursor,
    * we need to enforce the condition TOKEN(id) > TOKEN(cursor_id), which is realized here by: id TGT cursor_id
    */

    if (helper.isNotUndefinedAndNotNull(offsetCursor)) {
      let decoded_cursor = JSON.parse(this.base64Decode(offsetCursor));
      let cursorId = decoded_cursor['<%- idAttribute -%>'];
      let cursorSearchCondition = new searchArg({field: '<%- idAttribute -%>', value: {value: cursorId}, operator:'tgt', search:undefined});
      if (helper.isNotUndefinedAndNotNull(search)) {
        // -- Use *both* the given search condition and the cursor --
        searchTerms = new searchArg({field: null, value: null, operator: 'and', search:[search, cursorSearchCondition]});
      } else {
        // -- Use only the cursor --
        searchTerms = cursorSearchCondition;
      }
    }

    // === Construct CQL statement ===

    if (searchTerms !== undefined) {

      //check
      if(typeof searchTerms !== 'object') {
        throw new Error('Illegal "search" argument type, it must be an object.');
      }

      if (searchTerms.value && searchTerms.value.value) {
        searchTerms = new searchArg(searchTerms);
      }
      arg_cassandra = ' ' + searchTerms.toCassandra('<%- idAttribute -%>', filteringAllowed) + ';';
    }

    let query = 'SELECT * FROM <%- namePl -%>' + arg_cassandra;
    
    // === Set page size if needed ===

    let options = {};
    if (pagination && pagination.limit) {
      options.fetchSize = parseInt(pagination.limit);
    }

    // === Call to database ===

    const result = await client.execute(query, [], options);

    // === Construct return object ===

    const rows = result.rows.map(row => {
      let edge = {};
      let rowAs<%- name -%> = new <%- name -%>(row);
      edge.node = rowAs<%- name -%>;
      edge.cursor = rowAs<%- name -%>.base64Enconde();
      return edge;
    });
    let nextCursor = null;
    let hasNextCursor = false;
    /*
    * The pageState attribute is where Cassandra stores its own version of a cursor.
    * We cannot use it directly, because Cassandra uses different conventions. 
    * But its presence shows that there is a following page.
    */
    if (helper.isNotUndefinedAndNotNull(result.pageState)) {
      let maxIndex = rows.length - 1;
      nextCursor = rows[maxIndex].cursor;
      hasNextCursor = true;
    }

    let pageInfo = {
      startCursor: nextCursor,
      hasNextPage: hasNextCursor
    }
    return {edges: rows, pageInfo: pageInfo};
  }

  <%# For a proper response at the end of the add-function, a SELECT query is performed to get the information from the database.
      Usually, this would be a bad idea, because Cassandra is said to be quick at writing, but slow at querying.
      However, this is only true for queries over *several partitions* (see https://www.scnsoft.com/blog/cassandra-performance), 
      but we are using only one node here (no DDM).
      Furthermore, we query for a single ID, so even in a distributed case, we wouldn't query over more than one partition. %>

  static async addOne(input){
    await validatorUtil.ifHasValidatorFunctionInvoke('validateForCreate', this, input);
    try{
      let inputCopy = JSON.parse(JSON.stringify(input));
      if (inputCopy.skipAssociationsExistenceChecks) {
        delete inputCopy.skipAssociationsExistenceChecks;
      }
      for (let key of Object.keys(inputCopy)) {
        if (!helper.isNotUndefinedAndNotNull(definition.attributes[key])) {
          delete inputCopy[key];
        }
        if (definition.attributes[key] === 'String' && inputCopy[key].indexOf("'") !== 0) {
          inputCopy[key] = `'${inputCopy[key]}'`;
        }
      }
      const fields = Object.keys(inputCopy).join(', ');
      const values = Object.values(inputCopy).join(', ');
      const query = 'INSERT INTO <%- namePl -%> (' + fields + ') VALUES (' + values + ')';
      let mutationResponse = await client.execute(query);
      let checkQuery = (await client.execute(`SELECT * FROM <%- namePl -%> WHERE <%- idAttribute -%> = ${input[definition.internalId]}`)).rows[0];
      let response = new <%- name -%>(checkQuery, mutationResponse);
      return response;
    }catch(error){
      throw error;
    }  
  }

  static async deleteOne(id){
    const query = `SELECT * FROM <%- namePl -%> WHERE <%- idAttribute -%> = ${id}`;
    let queryResponse = await client.execute(query);
    await validatorUtil.ifHasValidatorFunctionInvoke('validateForDelete', this, queryResponse.rows[0]);
    const mutation = `DELETE FROM <%- namePl -%> WHERE <%- idAttribute -%> = ${id}`;
    await client.execute(mutation);
    queryResponse = await client.execute(query);
    if (helper.isEmptyArray(queryResponse.rows)) {
      return 'Item successfully deleted';
    }
    throw new Error('Record was not deleted!');
  }

  static async updateOne(input){
      await validatorUtil.ifHasValidatorFunctionInvoke('validateForUpdate', this, input);
      try{
        let inputCopy = JSON.parse(JSON.stringify(input));
        if (inputCopy.skipAssociationsExistenceChecks) {
          delete inputCopy.skipAssociationsExistenceChecks;
        }
        for (let key of Object.keys(inputCopy)) {
          if (!helper.isNotUndefinedAndNotNull(definition.attributes[key])) {
            delete inputCopy[key];
          }
          if (definition.attributes[key] === 'String' && inputCopy[key].indexOf("'") !== 0) {
            inputCopy[key] = `'${inputCopy[key]}'`;
          }
        }
        let idValue = input[this.idAttribute()];
        delete inputCopy[this.idAttribute()];
        let inputKeys = Object.keys(inputCopy);
        let mutationResponse = {};
        if (inputKeys.length > 0) {
          let mutation = `UPDATE <%- namePl -%> SET `;
          mutation += inputKeys.map(key => `${key} = ${inputCopy[key]}`).join(', ');
          mutation += ` WHERE <%- idAttribute -%> = ${idValue};`;
          mutationResponse = await client.execute(mutation);
        }
        let checkQuery = (await client.execute(`SELECT * FROM <%- namePl -%> WHERE <%- idAttribute -%> = ${idValue}`)).rows[0];
        let response = new <%- name -%>(checkQuery, mutationResponse);
        return response;
      }catch(error){
        throw error;
      }
  }

  static async bulkAddCsv(context){

      let delim = context.request.body.delim;
      let cols = context.request.body.cols;
      let tmpFile = path.join(os.tmpdir(), uuidv4() + '.csv');

      await context.request.files.csv_file.mv(tmpFile);

        try {
          let addedZipFilePath = await fileTools.parseCsvStream(tmpFile, this, delim, cols);
              try {
                  console.log(`Sending ${addedZipFilePath} to the user.`);

                  let attach = [];
                  attach.push({
                      filename: path.basename("added_data.zip"),
                      path: addedZipFilePath
                  });

                  try {
                      let info = await email.sendEmail(helpersAcl.getTokenFromContext(context).email,
                        'ScienceDB batch add',
                        'Your data has been successfully added to the database.',
                        attach);
                      fileTools.deleteIfExists(addedZipFilePath);
                      console.log(info);
                  } catch(err) {
                      fileTools.deleteIfExists(addedZipFilePath);
                      console.error(err);
                  }

              } catch (error) {
                  console.error(error.message);
              }

              fs.unlinkSync(tmpFile);
          } catch(error) {
            try {
              let info = await email.sendEmail(helpersAcl.getTokenFromContext(context).email,
                  'ScienceDB batch add', `${error.message}`);
                  console.error(info);
              } catch(err) {
                  console.error(err);
              }

              fs.unlinkSync(tmpFile);
          }

  }

  static csvTableTemplate(){
    return helper.csvTableTemplate(<%- name -%>);
  }

  <% associations_temp = associationsArguments["to_many_through_sql_cross_table"]-%>
  <% for(let i=0; i < associations_temp.length; i++){ -%>

    <%=associations_temp[i].name%>FilterImpl ({search,order,pagination}){
      let options = {};

      if(search!== undefined){
        let arg = new searchArg(search);
        let arg_sequelize = arg.toSequelize();
        options['where'] = arg_sequelize;
      }

      return this.count<%- associations_temp[i].name_cp%>(options).then( items => {
        if(order !== undefined){
          options['order'] = order.map( (orderItem) => {return [ orderItem.field, orderItem.order]; } );
        }else if(pagination !== undefined){
          options['order'] = [ [models.<%=associations_temp[i].target_lc-%>.idAttribute(), "ASC"] ];
        }
        if(pagination !== undefined){
          options['offset'] = pagination.offset === undefined ? 0 : pagination.offset;
          options['limit'] = pagination.limit === undefined ? (items - options['offset']) : pagination.limit;
        }else{
          options['offset'] = 0;
          options['limit'] = items;
        }
        if(globals.LIMIT_RECORDS < options['limit']){
          throw new Error(`Request of total <%=associations_temp[i].name_lc%>Filter exceeds max limit of ${globals.LIMIT_RECORDS}. Please use pagination.`);
        }
        return this.get<%- associations_temp[i].name_cp%>(options);
      });
    }


    <%=associations_temp[i].name%>ConnectionImpl ({search,order,pagination}){
      //check valid pagination arguments
      let argsValid = (pagination === undefined) || (pagination.first && !pagination.before && !pagination.last) || (pagination.last && !pagination.after && !pagination.first);
      if (!argsValid) {
        throw new Error('Illegal cursor based pagination arguments. Use either "first" and optionally "after", or "last" and optionally "before"!');
      }
      let isForwardPagination = !pagination || !(pagination.last != undefined);
      let options = {};
      options['where'] = {};

      /*
       * Search conditions
       */
      if (search !== undefined) {
          let arg = new searchArg(search);
          let arg_sequelize = arg.toSequelize();
          options['where'] = arg_sequelize;
      }

      /*
       * Count
       */
      return this.count<%- associations_temp[i].name_cp%>(options).then( countA => {
        options['offset'] = 0;
        options['order'] = [];
        options['limit'] = countA;
        /*
         * Order conditions
         */
        if(order !== undefined) {
          options['order'] = order.map((orderItem) => {
            return [orderItem.field, orderItem.order];
          });
        }
        if( !options['order'].map( orderItem=>{return orderItem[0] }).includes(models.<%=associations_temp[i].target_lc-%>.idAttribute()) ){
          options['order'] = [ ...options['order'], ...[ [models.<%=associations_temp[i].target_lc-%>.idAttribute(), "ASC"] ]];
        }
        /*
         * Pagination conditions
         */
        if(pagination) {
          //forward
          if(isForwardPagination) {
            if(pagination.after) {
              let decoded_cursor = JSON.parse(<%- name -%>.base64Decode(pagination.after));
              options['where'] = {
                  ...options['where'],
                  ...helper.parseOrderCursor(options['order'], decoded_cursor, models.<%=associations_temp[i].target_lc-%>.idAttribute(), pagination.includeCursor)
              };
            }
          }else {//backward
            if(pagination.before) {
              let decoded_cursor = JSON.parse(<%- name -%>.base64Decode(pagination.before));
              options['where'] = {
                  ...options['where'],
                  ...helper.parseOrderCursorBefore(options['order'], decoded_cursor, models.<%=associations_temp[i].target_lc-%>.idAttribute(), pagination.includeCursor)
              };
            }
          }
        }
        //woptions: copy of {options} with only 'where' options
        let woptions = {};
        woptions['where'] = {...options['where']};

        /*
         *  Count (with only where-options)
         */
        return this.count<%- associations_temp[i].name_cp%>(woptions).then( countB => {
          /*
           * Limit conditions
           */
          if(pagination) {
            //forward
            if(isForwardPagination) {
              if(pagination.first) {
                options['limit'] = pagination.first;
              }
            } else {//backward
              if(pagination.last) {
                options['limit'] = pagination.last;
                options['offset'] = Math.max( (countB - pagination.last), 0 );
              }
            }
          }
          //check: limit
          if(globals.LIMIT_RECORDS < options['limit']) {
            throw new Error(`Request of total <%=associations_temp[i].target_lc_pl-%>Connection exceeds max limit of ${globals.LIMIT_RECORDS}. Please use pagination.`);
          }

          /*
           * Get records
           */
          return this.get<%- associations_temp[i].name_cp%>(options).then( records =>{
            let edges = [];
            let pageInfo = {
              hasPreviousPage: false,
              hasNextPage: false,
              startCursor: null,
              endCursor: null
            };
            //edges
            if(records.length > 0) {
              edges = records.map(record => {
                return {
                  node: record,
                  cursor: record.base64Enconde()
                }
              });
            }

            //forward
            if(isForwardPagination) {
              pageInfo = {
                hasPreviousPage: ( (countA - countB) > 0 ),
                hasNextPage: ( pagination&&pagination.first ? (countB > pagination.first) : false ),
                startCursor: (records.length > 0) ? edges[0].cursor : null,
                endCursor: (records.length > 0) ? edges[edges.length - 1].cursor : null
              }
            } else {//backward
              pageInfo = {
                hasPreviousPage: ( pagination&&pagination.last ? (countB > pagination.last) : false ),
                hasNextPage: ( (countA - countB) > 0 ),
                startCursor: (records.length > 0) ? edges[0].cursor : null,
                endCursor: (records.length > 0) ? edges[edges.length - 1].cursor : null
              }
            }
            return {edges, pageInfo};

          }).catch(error =>{
            throw error;
          });
        }).catch(error =>{
          throw error;
        });
      }).catch(error =>{
        throw error;
      });
    }

    countFiltered<%=associations_temp[i].name_cp%>Impl({search}){
      let options = {};
      if(search!== undefined){
        let arg = new searchArg(search);
        let arg_sequelize = arg.toSequelize();
        options['where'] = arg_sequelize;
      }
      return this.count<%- associations_temp[i].name_cp%>(options);
    }
  <%}-%>

<%# generic_to_one -%>
  <% associations_temp = associationsArguments["generic_to_one"]-%>
  <% for(let i=0; i < associations_temp.length; i++){ -%>
    
    async <%=associations_temp[i].name%>Impl({search}, context){
      /*
      YOUR CODE GOES HERE
      */
      throw new Error('<%=associations_temp[i].name%>Impl() is not implemented');
    }
  <%}-%>
  
<%# generic_to_many -%>
  <% associations_temp = associationsArguments["generic_to_many"]-%>
  <% for(let i=0; i < associations_temp.length; i++){ -%>

    async <%=associations_temp[i].name%>FilterImpl({search,order,pagination}, context){
      /*
      YOUR CODE GOES HERE
      */
      throw new Error('<%=associations_temp[i].name%>FilterImpl() is not implemented');
    }

    async <%=associations_temp[i].name%>ConnectionImpl ({search,order,pagination}, context){
      /*
      YOUR CODE GOES HERE
      */
      throw new Error('<%=associations_temp[i].name%>ConnectionImpl() is not implemented');
    }

    async countFiltered<%=associations_temp[i].name_cp%>Impl({search}, context){
      /*
      YOUR CODE GOES HERE
      */
      throw new Error('countFiltered<%- associations_temp[i].name_cp %>Impl() is not implemented');
    }
  <%}-%>

  <%- include('./includes/create-models-fieldMutations-cassandra', {op: "add"}); %> 
  <%- include('./includes/create-models-fieldMutations-cassandra', {op: "remove"}); %>
  <%- include('./includes/create-models-fieldMutations-generic-associations', {op: "add"}); %> 
  <%- include('./includes/create-models-fieldMutations-generic-associations', {op: "remove"}); %> 
  
  /**
   * idAttribute - Check whether an attribute "internalId" is given in the JSON model. If not the standard "id" is used instead.
   *
   * @return {type} Name of the attribute that functions as an internalId
   */

  static idAttribute() {
    return <%- name -%>.definition.id.name;
  }

  /**
   * idAttributeType - Return the Type of the internalId.
   *
   * @return {type} Type given in the JSON model
   */

  static idAttributeType() {
    return <%- name -%>.definition.id.type;
  }

  /**
   * getIdValue - Get the value of the idAttribute ("id", or "internalId") for an instance of <%- name -%>.
   *
   * @return {type} id value
   */

  getIdValue() {
    return this[<%- name -%>.idAttribute()]
  }

  static get definition(){
    return definition;
  }

  static base64Decode(cursor){
    return Buffer.from(cursor, 'base64').toString('utf-8');
  }

    base64Enconde(){
    return Buffer.from(JSON.stringify(this.stripAssociations())).toString('base64');
  }

  stripAssociations(){
    let attributes = Object.keys(<%- name -%>.definition.attributes);
  <%if( defaultId ){-%>attributes.push('<%- idAttribute -%>'); <%}-%>
    let data_values = _.pick(this, attributes);
    return data_values;
  }

  static externalIdsArray(){
    let externalIds = [];
    if(definition.externalIds){
      externalIds = definition.externalIds;
    }

    return externalIds;
  }

  static externalIdsObject(){
    return {
      <%for(let i=0; i < externalIds.length; i++){-%> <%=externalIds[i]-%>: '<%=attributes[ externalIds[i] ]-%>' <%if(i !== (externalIds.length -1) ){ -%>,<%}-%><%}-%>
    };
  }

}
